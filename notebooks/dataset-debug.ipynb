{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b1582e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T05:02:39.246767Z",
     "start_time": "2023-04-27T05:02:39.234530Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dfa27f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T05:08:31.475569Z",
     "start_time": "2023-04-27T05:08:29.356725Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from torchdrive.data import collate\n",
    "from torchdrive.datasets.rice import MultiCamDataset\n",
    "from torchdrive.notebook import display_img, display_color, display, to_pil_image\n",
    "from torchdrive.transforms.batch import NormalizeCarPosition\n",
    "\n",
    "a = MultiCamDataset(\n",
    "    index_file=\"../../openape/snapshots/out-mar23/index.txt\",\n",
    "    mask_dir=\"../../openape/masks\",\n",
    "    cameras=[\"main\", \"narrow\", \"fisheye\", \"leftpillar\", \"leftrepeater\", \"rightpillar\", \"rightrepeater\", \"backup\"],\n",
    "    cam_shape=(480, 640),\n",
    "    nframes_per_point=5,\n",
    "    limit_size=1000,\n",
    "    dynamic=True,\n",
    ")\n",
    "print(len(a))\n",
    "example = a[500]\n",
    "\n",
    "#transform = NormalizeCarPosition(start_frame=0)\n",
    "#batch = collate([example])\n",
    "#batch = transform(batch)\n",
    "\n",
    "#for cam in a.cameras:\n",
    "#    display_img(example.color[cam][0].float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a60e69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T05:08:31.870918Z",
     "start_time": "2023-04-27T05:08:31.803782Z"
    }
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "import math\n",
    "import torch\n",
    "from pythreejs import *\n",
    "from IPython.display import display\n",
    "from torchdrive.transforms.batch import (\n",
    "    NormalizeCarPosition,\n",
    "    Compose,\n",
    "    RandomRotation,\n",
    "    RandomTranslation,\n",
    ")\n",
    "\n",
    "batch = collate([example])\n",
    "transform=Compose(\n",
    "    NormalizeCarPosition(start_frame=0),\n",
    "    RandomRotation(),\n",
    "    #RandomTranslation(distances=(5.0, 5.0, 0.0)),\n",
    ")\n",
    "batch = transform(batch)\n",
    "\n",
    "SCALE = 3\n",
    "D = 256/SCALE\n",
    "W = 256/SCALE\n",
    "H = 12/SCALE\n",
    "\n",
    "view_width = 600\n",
    "view_height = 400\n",
    "camera = PerspectiveCamera( position=[-10, 6, 10], aspect=640/view_height)\n",
    "camera.up = (0, 0, 1)\n",
    "key_light = DirectionalLight(position=[0, 10, 10])\n",
    "ambient_light = AmbientLight()\n",
    "\n",
    "grid_helper1 = GridHelper(20, 20, '#888', '#444')\n",
    "grid_helper10 = GridHelper(100, 10, '#888', '#444')\n",
    "grid_helper1.rotateX(math.pi/2)\n",
    "grid_helper10.rotateX(math.pi/2)\n",
    "\n",
    "scene = Scene(children=[grid_helper1, grid_helper10, camera, key_light, ambient_light], background='#111')\n",
    "#frame = 0\n",
    "num_positions = batch.cam_T[0].size(1)\n",
    "for frame in [0, 3,4]:#range(num_positions):\n",
    "\n",
    "    # render car positions\n",
    "    T = batch.car_to_world(frame)\n",
    "    geo = AxesHelper(1)\n",
    "    geo.matrixAutoUpdate = False\n",
    "    geo.matrix = tuple(T.T.contiguous().view(-1).tolist())\n",
    "    scene.add([geo])\n",
    "\n",
    "    # render camera positions\n",
    "    for cam in batch.T:\n",
    "        T = batch.cam_to_world(cam, frame)\n",
    "        geo = AxesHelper(1)\n",
    "        geo.matrixAutoUpdate = False\n",
    "        geo.matrix = tuple(T.T.contiguous().view(-1).tolist())\n",
    "        scene.add([geo])\n",
    "\n",
    "#sphere.position = (0, 0, 0)\n",
    "renderer = Renderer(camera=camera, scene=scene, controls=[OrbitControls(controlling=camera)], width=view_width, height=view_height)\n",
    "display(renderer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c1ed92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T04:34:45.765877Z",
     "start_time": "2023-04-27T04:34:44.783822Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchdrive.transforms.depth import Project3D, BackprojectDepth\n",
    "from torchdrive.losses import multi_scale_projection_loss\n",
    "\n",
    "torch.set_printoptions(precision=3, sci_mode=False)\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# projecting from src to target\n",
    "offset = 1\n",
    "target_cam = \"main\"\n",
    "target_frame = 2\n",
    "src_cam = \"main\"\n",
    "src_frame = target_frame+offset\n",
    "\n",
    "batch = batch.to(device)\n",
    "\n",
    "target_color = batch.color[target_cam][:, target_frame].float()\n",
    "src_color = batch.color[src_cam][:, src_frame].float()\n",
    "h, w = src_color.shape[-2:]\n",
    "\n",
    "backproject_depth = BackprojectDepth(h, w).to(device)\n",
    "project_3d = Project3D(h, w).to(device)\n",
    "\n",
    "depth = torch.ones(1, 1, h//4, w//4, device=device) * 1\n",
    "depth.requires_grad = True\n",
    "\n",
    "src_K = batch.K[src_cam].clone()\n",
    "# convert to image space\n",
    "src_K[:, 0] *= backproject_depth.width\n",
    "src_K[:, 1] *= backproject_depth.height\n",
    "\n",
    "target_K = batch.K[target_cam].clone()\n",
    "# convert to image space\n",
    "target_K[:, 0] *= backproject_depth.width\n",
    "target_K[:, 1] *= backproject_depth.height\n",
    "target_inv_K = target_K.pinverse()\n",
    "\n",
    "optimizer = torch.optim.AdamW([depth], lr=1e-2)\n",
    "for i in range(1):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    target_depth = F.interpolate(depth, scale_factor=4, mode='bilinear')\n",
    "\n",
    "    # convert points to world\n",
    "    target_cam_to_world = batch.cam_to_world(target_cam, target_frame)\n",
    "    world_points = backproject_depth(\n",
    "        target_depth, target_inv_K, target_cam_to_world\n",
    "    ).clone()\n",
    "\n",
    "    #print(world_points[0, :, 0])\n",
    "\n",
    "    # (world to cam) * camera motion\n",
    "    world_to_src_cam = batch.world_to_cam(src_cam, src_frame)\n",
    "    pix_coords = project_3d(world_points, src_K, world_to_src_cam)\n",
    "\n",
    "    proj_color = F.grid_sample(\n",
    "        src_color,\n",
    "        pix_coords,\n",
    "        mode=\"bilinear\",\n",
    "        padding_mode=\"border\",\n",
    "        align_corners=False,\n",
    "    )\n",
    "    \n",
    "    proj_loss = multi_scale_projection_loss(proj_color, target_color, scales=6)\n",
    "    loss = proj_loss.mean()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 200 == 0:\n",
    "        print(i, loss, target_depth.aminmax())\n",
    "display_color(proj_loss[0, 0])\n",
    "display_img(src_color[0])\n",
    "print(\"proj\")\n",
    "display_img(proj_color[0])\n",
    "print(\"target\")\n",
    "display_img(target_color[0])\n",
    "diff = (target_color[0]-proj_color[0]).abs().mean(dim=0)\n",
    "print(diff.sum(), diff.aminmax())\n",
    "display_color(diff)\n",
    "print(\"depth\", target_depth.shape)\n",
    "display_color(target_depth[0, 0])\n",
    "display_color(1/target_depth[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3ac6a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7044255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openape",
   "language": "python",
   "name": "openape"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
